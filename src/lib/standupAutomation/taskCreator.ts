/**
 * Task Creator Service
 * Creates Claude Code requirement files for automated analysis tasks
 */

import { logger } from '@/lib/logger';
import { createRequirement } from '@/app/Claude/lib/claudeCodeManager';
import { goalDb, goalHubDb } from '@/app/db';
import { projectDb } from '@/lib/project_database';
import { TaskType, TaskCreationRequest, CreatedTask, GoalCandidate } from './types';

/**
 * Build prompt for goal analysis task
 */
function buildGoalAnalysisPrompt(
  goalId: string,
  goalTitle: string,
  goalDescription: string | null,
  contextName?: string
): string {
  return `# Automated Goal Analysis: ${goalTitle}

## Context
This analysis was auto-generated by the Standup Automation Engine.

## Goal Information
- **ID:** \`${goalId}\`
- **Title:** ${goalTitle}
- **Description:** ${goalDescription || 'No description provided'}
${contextName ? `- **Context:** ${contextName}` : ''}

## Your Task

Perform a comprehensive analysis of this goal:

### 1. Codebase Exploration
- Search for files and components related to this goal
- Understand the current architecture and patterns
- Identify potential dependencies

### 2. Feasibility Analysis
- What changes are needed to achieve this goal?
- Are there any blockers or prerequisites?
- Estimated complexity (low/medium/high)?

### 3. Implementation Approach
- Recommended implementation strategy
- Key files to modify
- New files to create (if any)

### 4. Risk Assessment
- What could go wrong?
- Impact on existing functionality
- Testing requirements

## Output
Provide your analysis in a structured format with clear sections.
Include specific file paths and code examples where helpful.
`;
}

/**
 * Build prompt for goal breakdown task (hypothesis generation)
 */
function buildGoalBreakdownPrompt(
  goalId: string,
  goalTitle: string,
  goalDescription: string | null,
  contextName?: string
): string {
  return `# Goal Breakdown: ${goalTitle}

## Context
This breakdown was auto-generated by the Standup Automation Engine.
The purpose is to create testable hypotheses (success criteria) for the goal.

## Goal Information
- **ID:** \`${goalId}\`
- **Title:** ${goalTitle}
- **Description:** ${goalDescription || 'No description provided'}
${contextName ? `- **Context:** ${contextName}` : ''}

## Your Task

Break this goal down into verifiable hypotheses (success criteria):

### 1. Understand the Goal
- What does success look like for this goal?
- Who benefits from this goal being completed?
- What's the scope of the change?

### 2. Generate Hypotheses
For each hypothesis, define:
- **Title**: Short name for the criterion
- **Description**: What needs to be true for this to be verified
- **Evidence**: How to verify this is complete
- **Dependencies**: What needs to happen first

### 3. Output Format
Please provide hypotheses that can be created via API:

\`\`\`json
{
  "hypotheses": [
    {
      "title": "Hypothesis name",
      "description": "What this hypothesis tests",
      "evidence_needed": "How to verify completion"
    }
  ]
}
\`\`\`

After analysis, call the API to create hypotheses:
\`\`\`bash
curl -X POST "http://localhost:3000/api/goal-hypothesis" \\
  -H "Content-Type: application/json" \\
  -d '{"goalId": "${goalId}", "title": "...", "description": "..."}'
\`\`\`
`;
}

/**
 * Build prompt for progress check task
 */
function buildProgressCheckPrompt(
  goalId: string,
  goalTitle: string,
  hypotheses: Array<{ title: string; status: string }>,
  contextName?: string
): string {
  const hypothesisList = hypotheses
    .map(h => `- [${h.status.toUpperCase()}] ${h.title}`)
    .join('\n');

  return `# Progress Check: ${goalTitle}

## Context
This progress check was auto-generated by the Standup Automation Engine.
Purpose: Verify implementation progress against defined hypotheses.

## Goal Information
- **ID:** \`${goalId}\`
- **Title:** ${goalTitle}
${contextName ? `- **Context:** ${contextName}` : ''}

## Current Hypotheses
${hypothesisList || 'No hypotheses defined yet.'}

## Your Task

Verify the current implementation status:

### 1. Check Each Hypothesis
For each unverified hypothesis, determine:
- Has the work been completed?
- Is there evidence in the codebase?
- Are tests passing?

### 2. Update Hypothesis Status
For any verified hypotheses, call the API:
\`\`\`bash
curl -X PUT "http://localhost:3000/api/goal-hypothesis" \\
  -H "Content-Type: application/json" \\
  -d '{"id": "<hypothesis_id>", "status": "verified", "evidence": "..."}'
\`\`\`

### 3. Report Findings
- Which hypotheses are now verified?
- What work remains?
- Any blockers identified?

### 4. Goal Status Update
If all hypotheses are verified, update the goal status:
\`\`\`bash
curl -X PUT "http://localhost:3000/api/goals" \\
  -H "Content-Type: application/json" \\
  -d '{"id": "${goalId}", "status": "done"}'
\`\`\`
`;
}

/**
 * Build prompt for blocker resolution task
 */
function buildBlockerResolutionPrompt(
  goalId: string,
  goalTitle: string,
  blockers: string[],
  contextName?: string
): string {
  const blockerList = blockers.map(b => `- ${b}`).join('\n');

  return `# Blocker Resolution: ${goalTitle}

## Context
This analysis was auto-generated by the Standup Automation Engine.
Purpose: Analyze and propose solutions for identified blockers.

## Goal Information
- **ID:** \`${goalId}\`
- **Title:** ${goalTitle}
${contextName ? `- **Context:** ${contextName}` : ''}

## Identified Blockers
${blockerList || 'No specific blockers documented.'}

## Your Task

Analyze each blocker and propose solutions:

### 1. Blocker Analysis
For each blocker:
- What is the root cause?
- Is this a technical or process issue?
- What's the impact on the goal?

### 2. Solution Proposals
For each blocker, provide:
- Recommended solution
- Steps to implement
- Alternative approaches (if any)
- Estimated effort

### 3. Action Items
Create a prioritized list of actions to unblock progress.

### 4. Goal Status Update
If blockers are resolved, update status:
\`\`\`bash
curl -X PUT "http://localhost:3000/api/goals" \\
  -H "Content-Type: application/json" \\
  -d '{"id": "${goalId}", "status": "in_progress"}'
\`\`\`
`;
}

/**
 * Build prompt for new goal candidates review
 */
function buildGoalCandidatesReviewPrompt(
  projectId: string,
  projectName: string,
  candidates: GoalCandidate[]
): string {
  const candidateList = candidates
    .map((c, i) => `
### Candidate ${i + 1}: ${c.title}
- **Priority Score:** ${c.priorityScore}/100
- **Category:** ${c.category}
- **Source:** ${c.source}
- **Description:** ${c.description}
- **Reasoning:** ${c.reasoning}
${c.suggestedContext ? `- **Suggested Context:** ${c.suggestedContext}` : ''}
`)
    .join('\n');

  return `# Goal Candidates Review

## Context
These goal candidates were auto-generated by the Standup Automation Engine.
Purpose: Review and validate before adding to the project.

## Project: ${projectName} (${projectId})

## Generated Candidates
${candidateList}

## Your Task

Review each candidate and determine:

### 1. Validation
For each candidate:
- Is the goal clear and achievable?
- Does it align with project direction?
- Are there conflicts with existing goals?

### 2. Refinements
Suggest improvements to:
- Goal titles (make more specific)
- Descriptions (add success criteria)
- Priority scores (adjust based on context)

### 3. Recommendations
Which candidates should be:
- **Approved**: Ready to add as goals
- **Modified**: Need changes before approval
- **Rejected**: Not suitable at this time

### 4. Create Approved Goals
For approved candidates, call:
\`\`\`bash
curl -X POST "http://localhost:3000/api/goals" \\
  -H "Content-Type: application/json" \\
  -d '{
    "projectId": "${projectId}",
    "title": "...",
    "description": "...",
    "status": "open",
    "category": "..."
  }'
\`\`\`
`;
}

/**
 * Create a Claude Code requirement for a task
 */
export async function createTask(request: TaskCreationRequest): Promise<CreatedTask | null> {
  try {
    const { type, goalId, goalTitle, projectPath, contextName, additionalContext } = request;

    // Get goal details if needed
    const goal = goalDb.getGoalById(goalId);
    let prompt: string;

    switch (type) {
      case 'goal_analysis': {
        prompt = buildGoalAnalysisPrompt(goalId, goalTitle, goal?.description || null, contextName);
        break;
      }
      case 'goal_breakdown': {
        prompt = buildGoalBreakdownPrompt(goalId, goalTitle, goal?.description || null, contextName);
        break;
      }
      case 'progress_check': {
        const hypotheses = goalHubDb.hypotheses.getByGoalId(goalId);
        const hypothesisData = hypotheses.map(h => ({ title: h.title, status: h.status }));
        prompt = buildProgressCheckPrompt(goalId, goalTitle, hypothesisData, contextName);
        break;
      }
      case 'blocker_resolution': {
        const blockers = additionalContext ? additionalContext.split('|') : [];
        prompt = buildBlockerResolutionPrompt(goalId, goalTitle, blockers, contextName);
        break;
      }
      default:
        logger.error('Unknown task type:', type);
        return null;
    }

    // Generate requirement name
    const timestamp = Date.now().toString(36);
    const requirementName = `auto-${type}-${goalId.slice(0, 8)}-${timestamp}`;

    logger.info('Creating automated task requirement', {
      type,
      requirementName,
      projectPath,
      goalId,
    });

    // Create the requirement file
    const result = createRequirement(projectPath, requirementName, prompt, true);

    if (!result.success) {
      logger.error('Failed to create task requirement:', { error: result.error });
      return null;
    }

    logger.info('Automated task requirement created', {
      requirementName,
      filePath: result.filePath,
    });

    return {
      requirementName,
      requirementPath: result.filePath || '',
      taskType: type,
      goalId,
      createdAt: new Date().toISOString(),
    };
  } catch (error) {
    logger.error('Error creating task:', error);
    return null;
  }
}

/**
 * Create task for reviewing goal candidates
 */
export async function createCandidatesReviewTask(
  projectId: string,
  projectPath: string,
  candidates: GoalCandidate[]
): Promise<CreatedTask | null> {
  try {
    const project = projectDb.getProject(projectId);
    const projectName = project?.name || 'Unknown Project';

    const prompt = buildGoalCandidatesReviewPrompt(projectId, projectName, candidates);

    const timestamp = Date.now().toString(36);
    const requirementName = `auto-candidates-review-${timestamp}`;

    logger.info('Creating candidates review task', {
      requirementName,
      projectPath,
      candidatesCount: candidates.length,
    });

    const result = createRequirement(projectPath, requirementName, prompt, true);

    if (!result.success) {
      logger.error('Failed to create candidates review task:', { error: result.error });
      return null;
    }

    return {
      requirementName,
      requirementPath: result.filePath || '',
      taskType: 'goal_analysis', // Close enough type
      goalId: '', // No specific goal
      createdAt: new Date().toISOString(),
    };
  } catch (error) {
    logger.error('Error creating candidates review task:', error);
    return null;
  }
}

/**
 * Create multiple tasks in batch
 */
export async function createTasksBatch(
  requests: TaskCreationRequest[]
): Promise<CreatedTask[]> {
  const createdTasks: CreatedTask[] = [];

  for (const request of requests) {
    const task = await createTask(request);
    if (task) {
      createdTasks.push(task);
    }
    // Small delay between task creations
    await new Promise(resolve => setTimeout(resolve, 100));
  }

  return createdTasks;
}
